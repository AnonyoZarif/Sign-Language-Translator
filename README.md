# Sign-Language-Translator
**Work in Progress** (The code will get the comments in the upcoming days)

Neural Network created using Sequential architecture and combination of LSTM and Dense layers in order to translate American Sign Language (ASL) into text.

<p align="center"> <img src="img/1.gif" alt="drawing" width="450"/> </p>


## Description

This project provides an opportunity for people to train their own Neural Network by recording their own dataset of ASL signs in an intuitive and simple manner.
The whole project can be split into three separate parts:
1. Data collection;
2. Model training;
3. Real time predictions.

## Data Collection

TBA

In order for a user to collect data and create their own dataset, the [data_collection.py](https://github.com/dgovor/Sign-Language-Translator/blob/main/data_collection.py) is used. The script is organized in a way that it would be easy to configure your own preferences and options, such as the signs the user would like to add to their dataset, the number of sequences for each sign, the number of frames for each sequence, and the path where the user would like to store the dataset. Onces these parameters were set and the script is running, the user can start recording the data.

<p align="center"> <img src="img/2.gif" alt="drawing" width="450"/> </p>

## Model Training

TBA

## Real Time Predictions

TBA
